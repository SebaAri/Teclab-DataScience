{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd58cb2",
   "metadata": {},
   "source": [
    "# Machine learning: Clasificación y Regresión: API-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e06f53",
   "metadata": {},
   "source": [
    "# Importamos las librerías que nos indica el punto a):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51071591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b877a9",
   "metadata": {},
   "source": [
    "# Importamos las librerías necesarias para el punto b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042d8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f24e96",
   "metadata": {},
   "source": [
    "# Cargamos el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8ea6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo tenemos guardado en mi computadora personal:\n",
    "data = pd.read_csv(\"C:\\Técnico-Universitario-Data-Science\\Machine-Learning-Clasificación-Y-Regresión\\M2\\AmesHousing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd9be64-ab05-46e6-881a-0dc33c4e17c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay valores NaN en el DataFrame después de la imputación.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Función para imputar valores NaN en columnas numéricas y categóricas:\n",
    "def imputar_nans(data):\n",
    "    # Imputación para columnas numéricas:\n",
    "    numeric_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    numeric_columns = data.select_dtypes(include=[\"number\"]).columns\n",
    "    data[numeric_columns] = numeric_imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "    # Imputación para columnas categóricas:\n",
    "    categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    categorical_columns = data.select_dtypes(include=[\"object\"]).columns\n",
    "    data[categorical_columns] = categorical_imputer.fit_transform(data[categorical_columns])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Imputamos NaNs del DataFrame:\n",
    "df_imputed = imputar_nans(data)\n",
    "\n",
    "# Verificamos si quedan NaNs en el DataFrame después de la imputación:\n",
    "nans_despues_imputacion = df_imputed.isna().any().any()\n",
    "\n",
    "if not nans_despues_imputacion:\n",
    "    print(\"No hay valores NaN en el DataFrame después de la imputación.\")\n",
    "else:\n",
    "    print(\"Aún hay valores NaN en el DataFrame después de la imputación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1488d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opción 1: MAE = 27.25\n",
      "Opción 2: MAE = 24.735787873515136\n",
      "Opción 3: MAE = 26.15680225377696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ariel\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado 'data' que quieres imputar\n",
    "data = pd.DataFrame({\n",
    "    'numeric_column': [1, 2, 3, None, 5],\n",
    "    'categorical_column': ['a', 'b', None, 'a', 'b'],\n",
    "    'SalePrice': [100, 200, 150, 250, None]  # Agregar columna objetivo\n",
    "})\n",
    "\n",
    "# Definir la función para imputar NaNs\n",
    "def imputar_nans(data):\n",
    "    numeric_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    numeric_columns = data.select_dtypes(include=[\"number\"]).columns\n",
    "    data[numeric_columns] = numeric_imputer.fit_transform(data[numeric_columns])\n",
    "\n",
    "    categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    categorical_columns = data.select_dtypes(include=[\"object\"]).columns\n",
    "    data[categorical_columns] = categorical_imputer.fit_transform(data[categorical_columns])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Llamar a la función para imputar NaNs\n",
    "df_imputed = imputar_nans(data)\n",
    "\n",
    "# Convertir todos los nombres de características a cadenas\n",
    "df_imputed.columns = df_imputed.columns.astype(str)\n",
    "\n",
    "# Aplicar One-Hot Encoding a las columnas categóricas\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_data = encoder.fit_transform(df_imputed.select_dtypes(include=['object']))\n",
    "encoded_columns = encoder.get_feature_names_out(df_imputed.select_dtypes(include=['object']).columns)\n",
    "df_encoded = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
    "\n",
    "# Concatenar las columnas codificadas con las columnas numéricas\n",
    "df_final = pd.concat([df_imputed.drop(df_imputed.select_dtypes(include=['object']), axis=1), df_encoded], axis=1)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X = df_final.drop(\"SalePrice\", axis=1)\n",
    "y = df_final[\"SalePrice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir los modelos SVR con diferentes kernels\n",
    "modelos = [\n",
    "    SVR(kernel='linear'),\n",
    "    SVR(kernel='rbf'),\n",
    "    SVR(kernel='poly')\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar los modelos\n",
    "for i, modelo in enumerate(modelos, start=1):\n",
    "    modelo.fit(X, y)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Opción {i}: MAE = {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589bb2d-5f98-40f9-811c-66ee72e29a92",
   "metadata": {},
   "source": [
    "# Elegimos la opción 2: SVR con kernel radial ya que posee menos MAE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
